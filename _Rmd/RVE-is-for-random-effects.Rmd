---
layout: post
title: Robust variance estimation is for random effects models
date: August 14, 2017
tags: [meta-analysis, sandwiches, R]
---

One of the methodological decisions that must be made when conducting a meta-analysis is whether to use a fixed effects (FE) model or a random effects (RE) model. Oftentimes, this decision is framed in terms of whether there is heterogeneity in the effect sizes to be synthesized. According to this line of thinking, the FE model is appropriate if one is willing to assume all all of the studies to be synthesized are estimating a common effect size parameter, while the RE model is appropriate if the true effect size parameters are  (possibly) heterogeneous. Here, the FE model is _nested_ within the RE model, meaning that the FE model is simply a special case of the RE model with heterogeneity equal to zero. Furthermore, because RE is strictly more general (making less restrictive assumptions), it should almost always be preferred. However, this is not the only way of thinking about the distinction between these models. 

A more nuanced perspective, articulated in [Hedges and Vevea (1998)](https://dx.doi.org/10.1037/1082-989X.3.4.486) and recently in [Rice, Higgins, and Lumley (2017)](https://dx.doi.org/10.1111/rssa.12275), is that the choice between FE and RE models should be made on the basis of one's inference model. Here, the FE model is appropriate if the goal of the meta-analysis is only to summarize the set of studies identified for inclusion, without drawing generalizations to any larger population of studies. This is sometimes called _conditional inference_ because the analysis treats the true effect sizes as fixed quantities (i.e., it conditions on the true effects), even if they were sampled from a larger population. Crucially, conditional inference with the FE model is a valid approach _even if the true effects are heterogeneous_. On the other hand, the RE model is appropriate if the goal of the meta-analysis is to draw inferences about a larger population of studies, from which the included studies are sampled. From this perspective, one could argue that it is actually the RE model that makes stronger assumptions, insofar as it requires assuming that the studies to be synthesized are representative of some larger population, which is often only vaguely specified. 

This post is not going to settle the question of which inferential model is more appropriate. Instead, I raise the distinction because I want to highlight how robust variance estimation (RVE) methods fit into the picture.
In short: __*RVE is only for random effects models*__, in the sense that RVE is based on an inference model where the included studies comprise a sample from a larger population. If one adopts the FE inference model and limits generalizations to the set of included studies, RVE _will not work_ in the presence of between-study heterogeneity.  

Now let me back up for a second because you might be asking: "What's RVE?" RVE is a statistical technique for estimating standard errors, calculating confidence intervals, and conducting hypothesis tests about mean effect size parameters (and more generally, meta-regression coefficients) that relies on weaker assumptions than standard methods. [Sidik and Jonkman (2006)](https://dx.doi.org/10.1016/j.csda.2005.07.019) argued for the use of RVE in univariate meta-analysis models (where each study contributes a single effect size estimate) because RVE produces more accurate variance estimates and confidence intervals than conventional methods.[^1] [Hedges, Tipton, and Johnson (2010)](https://dx.doi.org/10.1002/jrsm.5) introduced RVE methods for the more general case of meta-regression models with dependent effect sizes, where studies can contribute multiple, possibly correlated effect size estimates. In practice, it is quite common to have studies that contribute multiple effect size estimates but do not also provide the information necessary to accurately estimate their correlation. Without that information, other methods of handling dependence become tenuous, while  RVE estimates are robust to mistaken assumptions about the correlation. Because of these advantages, RVE is increasingly common in meta-analyses within education, psychology, and other social science fields.

The title of [Sidik and Jonkman's (2006)](https://dx.doi.org/10.1016/j.csda.2005.07.019) paper should make it clear that RVE is for random effects models (it's called "Robust variance estimation for random effects meta-analysis"), but the point is not quite as explicit in [Hedges, Tipton, and Johnson (2010)](https://dx.doi.org/10.1002/jrsm.5). Instead, the random effects inference model is implicit in the asymptotic assumptions by which RVE is justified. Less directly, the connection between RVE and the RE inference model can also be seen in the working models introduced for use with RVE, which are based on a random effects model. My point in the remainder of this post is that RVE is _only_ for the random effects inference model. It won't work with the FE model for conditional inference. To see why it fails with the FE model, let's look first at the usual univariate meta-analysis setup.

## Univariate meta-analysis

Say that we have a collection of $K$ studies, each of which contributes a single effect size estimate, $T_i$ for $i = 1,...,K$. Following the usual meta-analysis incantations, we assume that $T_i$ is an unbiased estimate of the true effect size parameter $\theta_i$ and that the sampling variance of $T_i$ (conditional on $\theta_i$) is a known constant $v_i$. So $\text{E}(T_i|\theta_i) = \theta_i$ and $\text{Var}(T_i | \theta_i) = v_i$. The RE model goes on to make assumptions about the distribution of the effect size parameters---typically that they are mutually independent and normally distributed with $\theta_1,...,\theta_K \stackrel{iid}{\sim} N(\mu, \tau^2)$. And then the main parameters of interest are the population mean $\mu$ and variance $\tau^2$.  

The FE model, on the other hand, just stops without making further distributional assumptions and works directly with the conditional distributions. The main parameter of interest is then the precision-weighted mean effect:
$$
\tilde\theta = \frac{1}{W} \sum_{i=1}^K \frac{\theta_i}{v_i}, \quad \text{where} \quad W = \sum_{i=1}^K 1 / v_i.
$$
If all of the effect sizes are equal, then we can interpret $\tilde\theta$ as the common effect studied across all $K$ studies. If the effects are actually heterogeneous, then $\tilde\theta$ is a particular, more-or-less arbitrarily weighted average of the effect size parameters.[^2] In FE meta-analysis, the average effect parameter is estimated by taking a weighted average of the effect size estimates, with weights proportional to the inverse sampling variances (just like in the definition of the target parameter):
$$
\tilde{T} = \frac{1}{W} \sum_{i=1}^K \frac{T_i}{v_i}
$$
Conditional on the true effects, $\text{E}\left(\tilde{T} | \theta_1,...,\theta_K\right) = \tilde\theta$ and $\text{Var}\left(\tilde{T} | \theta_1,...,\theta_K\right) = 1 / W$. Note here that the variance of $\tilde{T}$ doesn't need to be estimated---because $v_1,...,v_K$ are assumed to be known constants, $1 / W$ can just be _calculated_ without worrying about any error in estimation. But what if we tried to use robust variance estimation instead?

For the simple case of univariate meta-analysis (with no meta-regression parameters), the robust estimator of $\text{Var}({\tilde{T}})$ is 
$$
V^R = \frac{1}{W^2} \sum_{i=1}^K \frac{(T_i - \tilde{T})^2}{v_i^2 (1 - h_i)},
$$
where $h_i = 1 / (v_i W)$ ([Sidik & Jonkman, 2006)](https://dx.doi.org/10.1016/j.csda.2005.07.019). Conditional on the effect size parameters, this estimator has expectation
$$
\text{E}\left(V^R | \theta_1,...,\theta_K\right) = \frac{1}{W} + \frac{1}{W^2} \sum_{i=1}^K \frac{(\theta_i - \tilde\theta)^2}{v_i^2 (1 - h_i)}.
$$
If the effect size parameters are heterogeneous, then this estimator will be _upwardly biased_ because of the second term, which captures variability in the effect size parameters.[^3] Only if the effect size parameters are homogeneous (as in the "common effect" interpretation of the FE model) will the robust variance estimator be unbiased for the true variance of $\tilde{T}$ (because in this case the second term in the above expression reduces to zero). 

Of course, this is all much ado about nothing for the univariate meta-analysis model because we can just calculate the variance $1 / W$, no estimation necessary, and thus no need for RVE (nor for Knapp-Hartung).[^4] But what if your meta-analysis involves dependent effect size estimates?

## Meta-analysis with dependent effects

Now let's consider a scenario where we have a collection of $K$ studies, each of which contributes _one or possibly multiple_ effect size estimates, $T_{i1},...,T_{in_i}$ for $i = 1,...,K$ and $n_i \geq 1$. As previously, we assume that $T_{ij}$ is an unbiased estimate of the true effect size parameter $\theta_{ij}$ and that the sampling variance of $T_{ij}$ (conditional on $\theta_{ij}$) is a known constant $v_{ij}$. But now, we allow that it is possible that $\text{corr}\left(T_{ij}, T_{ik} \left| \theta_{ij}, \theta_{ik} \right. \right) = \rho_{ijk} \neq 0$. Moving to matrix notation, let $\mathbf{T}_i$ be the $n_i \times 1$ vector of effect size estimates, $\boldsymbol\theta_i$ be the corresponding parameter vector, and $\mathbf{V}_i$ be the conditional sampling variance-covariance matrix of $\mathbf{T}_i$, i.e., $\text{Var}(\mathbf{T}_i | \boldsymbol\theta_i) = \mathbf{V}_i$. 

Suppose that we want to estimate an overall average across all the effect sizes in all of the included studies. 


[^1]: RVE is also helpful in univariate meta-analysis models if there are concerns about the accuracy of the sampling variances for the effect size estimates. For instance, sampling variances are typically estimated using asymptotic approximations that are valid if based on a large enough sample. If some included studies have quite small sample sizes, the asymptotic approximations might not be very good, and so the sampling variances could be crumby.  
[^2]: [Rice and company](https://dx.doi.org/10.1111/rssa.12275) discuss some justifications for focusing on the precision-weighted average of the effects. Other weighting schemes could be entertained too, like simple averages or sample size weighted-averages, but these are just as hard to justify from first principles. 
[^3]: The [Hartung-Knapp](https://dx.doi.org/10.1002/sim.791) variance estimator has a very similar problem. 
[^4]: Unless the sampling variances are inaccurate...then it seems like you'd be SOL before even considering whether $1 / W$ is a good estimate of $\text{Var}({\tilde{T}})$, since the FE _target parameter_ $\tilde\theta$ would be ill defined.
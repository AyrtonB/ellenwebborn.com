---
layout: post
title: Testing for level-$\alpha$ tests
date: October 11, 2016
tags: [simulation]
---

Some of my current work involves examining the rejection rates of different types of hypothesis testing procedures that are based on heteroskedasticity-robust or cluster-robust variance estimators. In some cases, we are examining the rejection rates of a fairly large number of alternative tests under a fairly large number of data-generating mechanisms. 

One of the questions of interest is which of these tests are level-$\alpha$, meaning that they have true rejection rates that are _always_ less than or equal to the nominal Type-I error rate. I'd like to find a formal hypothesis test that can be used to address this question. Here's the statistical setup.

Consider first the performance of a single hypothesis testing procedure, across a range of different data-generating models/conditions (where model includes specific values of the relevant parameters, such as the degree of heteroskedasticity). Suppose that there are $M$ models in all, and that the true rejection rates of the test under these models are $\pi_1,...,\pi_M$. For each model, we observe an independent, binomial random sample based on $N$ trials:

$$P_m \sim \text{Bin}\left(\pi_m, N\right)$$

for $m = 1,...,M$. Typical values of $N$ range from 2000 and 10000.

The goal is to test the hypothesis 

$$H_0: \bigcap_{m = 1,...,m} \pi_m \leq \alpha$$ 

against the alternative that $H_A: \pi_m > \alpha$ for at least one model $m$. It seems straight-forward to generate binomial samples under the null, but I'm trying to figure out the best test statistic to use. 

Beyond that, there's also the question of how to apply such a test to a set of several different procedures in order to identify the subset of procedures that are level-$\alpha$ (an issue is that the $P_m$'s are likely to be correlated across procedures) and then also to identify the procedure(s) with the most accurate rejection rates from among the subset of level-$\alpha$ procedures.
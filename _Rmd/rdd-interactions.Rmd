---
layout: post
title: Regression discontinuities with covariate interactions in the `rdd` package
date: January 24, 2016
tags: [econometrics, R]
---

The [`rdd` package](https://cran.r-project.org/web/packages/rdd/) provides a set of methods for analysis of regression discontinuity designs (RDDs), including methods to estimate marginal average treatment effects by local linear regression. I was working with the package recently and was obtaining counter-intuitive results for the treatment effect estimate in a sharp RDD model. The issue arises because, in models with additional covariates (beyond just the running variable, treatment indicator, and interaction), the main estimation function in `rdd` uses a specification in which covariates are always interacted with the treatment indicator. In this post, I'll demonstrate the problem and comment on potential fixes. 

### A simulated example

To make things more concrete, here's a hypothetical RDD. I'll use $R$ to denote the running variable, with the threshold set at zero; $T$ for the treatment indicator; and $Y$ for the outcome. $X_1$ is a continuous covariate that is correlated with $R$. $X_2$ is a categorical covariate with four levels that is independent of $X_1$ and $R$. In order to demonstrate the issue with covariate-by-treatment interactions, I use a model in which the effect of the treatment varies with $R$, $X_1$, and $X_2$: 


```{r}
set.seed(20160124)

simulate_RDD <- function(n = 2000, R = rnorm(n, mean = qnorm(.2))) {
  n <- length(R)
  T <- as.integer(R > 0)
  X1 <- 10 + 0.6 * (R - qnorm(.2)) + rnorm(n, sd = sqrt(1 - 0.6^2))
  X2 <- sample(LETTERS[1:4], n, replace = TRUE, prob = c(0.2, 0.3, 0.35, 0.15))
  Y0 <- 0.4 * R + 0.1 * (X1 - 10) + c(A = 0, B = 0.30, C = 0.40, D = 0.55)[X2] + rnorm(n, sd = 0.9)
  Y1 <- 0.35 + 0.3 * R + 0.18 * (X1 - 10) + c(A = -0.50, B = 0.30, C = 0.20, D = 0.60)[X2] + rnorm(n, sd = 0.9)
  Y <- (1 - T) * Y0 + T * Y1
  data.frame(R, T, X1, X2, Y0, Y1, Y)
}

RD_data <- simulate_RDD(n = 2000)
```

### Simple RDD analysis

The main estimand in a sharp RDD is the marginal average treatment effect (MATE)---that is, the average effect of treatment assignment for units right at/near the threshold of eligibility. Even though I simulated a treatment response surface that depends on the covariates $X_1,X_2$, it is not necessary to control for them in order to identify the MATE. Rather, it is sufficient to regress the outcome on the running variable, treatment indicator, and their interaction:

$$Y_i = \beta_0 + \beta_1 R_i + \beta_2 T_i + \beta_3 R_i T_i + \epsilon_i$$

In practice, this regression is usually estimated locally, within a certain bandwidth of the threshold, and using weights defined on the basis of some kernel. The default in the `rdd` package is to use a triangular edge kernel, with bandwidth chosen using a formula proposed by Imbens and Kalyanaraman. The following code uses `rdd` to estimate the MATE without controlling for covariates:

```{r, message=FALSE}
library(rdd)
bw <- with(RD_data, IKbandwidth(R, Y, cutpoint = 0))
rdd_simple <- RDestimate(Y ~ R, data = RD_data, cutpoint = 0, bw = bw)
summary(rdd_simple)
```

Using a bandwidth of `r round(bw, 2)`, the estimated marginal average treatment effect is `r round(rdd_simple$est[["LATE"]], 3)`. The figure below illustrates the discontinuity:

```{r, echo = FALSE, fig.width = 10, fig.height = 6}
library(ggplot2)
ggplot(RD_data, aes(R, Y, color = factor(T))) + 
  geom_point(alpha = 0.1) + 
  geom_smooth(method = "loess") + 
  geom_vline(xintercept = 0) + 
  theme_minimal() + 
  coord_cartesian(xlim = c(-1.5,1.5)) + 
  labs(color = "Treatment")
```

### RDD with covariates

The following table reports the estimates generated by `RDestimate` when controlling for neither, one, or both covariates. 
```{r}
RD_est <- function(mod, covariates) {
  RD_fit <- RDestimate(as.formula(paste(mod, covariates)), 
                       data = RD_data, cutpoint = 0)
  with(RD_fit, c(est = est[[1]], se = se[1], p = p[1]))
}

covariates <- list("No covariates" = "",
                "X1 only" = "| X1",
                "X2 only" = "| X2",
                "X1 + X2" = "| X1 + X2")

library(plyr)
ldply(covariates, RD_est, mod = "Y ~ R", .id = "Specification")
```

Despite using identical bandwidths, the estimates are drastically different from each other, with standard errors that are drastically larger than for the simple estimate without covariates. Confusingly, if I instead use two-stage least squares estimation with $T$ instrumenting for itself, I get entirely different estimates when covariates are included:

```{r}
ldply(covariates, RD_est, mod = "Y ~ R + T", .id = "Specification")
```

Using 2SLS, the MATE estimate is entirely insensitive to the inclusion of one or both covariates. 
This puzzling behavior occurs because, for sharp RDDs only, `RDestimate` always interacts the covariate(s) with the treatment indicator. Here is the relevant section of the function: 
```{r}
body(RDestimate)[[39]][[4]][[7]][[3]][[3]]
```

For a generic covariate $X$, the function uses the specification:

$$Y_i = \beta_0 + \beta_1 R_i + \beta_2 T_i + \beta_3 R_i T_i + \beta_4 X_i + \beta_5 X_i T_i + \epsilon_i, $$

while still taking $\beta_2$ to represent the MATE. This is problematic because, as soon as the $X_i T_i$ term is introduced into the model, $\beta_2$ represents the difference between treated and untreated units at the threshold (where $R_i = 0$) and where $X_i = 0$. Thus, including the $X_1$ interaction in the model means that $\beta_2$ is a difference extrapolated _way_ outside the support of the data, as in the following scatterplot of the outcome versus the covariate $X_1$:

```{r, echo = FALSE, fig.width = 10, fig.height = 6}
RD_data$w <- kernelwts(RD_data$R, center = 0, bw = bw)
blank_dat <- within(RD_data, {X1 <- 0})
ggplot(RD_data, aes(X1, Y, color = factor(T), weight = w)) + 
  geom_point(aes(alpha = w)) + 
  geom_smooth(method = "lm", fullrange = TRUE) + 
  geom_blank(data = blank_dat) +
  coord_cartesian(xlim = c(0,14)) + 
  labs(x = "X1", y = "Y", color = "T") + 
  scale_alpha_continuous(guide = FALSE) + 
  theme_minimal()
```

Similarly, including the $X_2$ interaction in the model means that $\beta_2$ will represent the marginal average treatment effect for only one of the categories of $X_2$, rather than as some sort of average across all four categories. 

### What to do about this
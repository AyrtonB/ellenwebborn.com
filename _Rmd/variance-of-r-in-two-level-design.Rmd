---
layout: post
title: Sampling variance of Pearson's r in a two-level design
date: April 15, 2018
tags: [effect-sizes, meta-analysis, delta-method, distribution-theory]
---

Consider Pearson's correlation coefficient, $r$, calculated from two variables $X$ and $Y$ with population correlation $\rho$. If one calculates $r$ from a simple random sample of $N$ observations, then the sampling variance of $r$ will be approximately

$$
\text{Var}(r) \approx \frac{1}{N}\left(1 - \rho^2\right)^2.
$$

But what if the observations are drawn from a multi-stage sample? If one uses the raw correlation between the observations (ignoring the multi-level structure), then the $r$ will actually be a weighted average of within-cluster and between-cluster correlations (Snijders & Bosker, 2012). Intuitively, I would expect that the sampling variance of the between-cluster correlation will be a function of the number of clusters (regardless of the number of observations per cluster), so the variance of $r$ from a multi-stage sample would not necessarily be the same as that from a simple random sample. What is the sampling variance of $r$ in this design?

Let me be more precise here by formalizing the sampling process. Suppose that we have a sample with $m$ clusters, $n_j$ observations in cluster $j$, and total sample size $N = \sum_{j=1}^m n_j$. Assume that 

$$
\begin{aligned}
X_{ij} &= \mu_x + v^x_j + e^x_{ij} \\
Y_{ij} &= \mu_y + v^y_j + e^y_{ij},
\end{aligned}
$$

for $i=1,...,n_j$ and $j=1,...,m$, where

$$
\begin{aligned}
\left[\begin{array}{c} v^x_j \\ v^y_j \end{array}\right] &\sim N\left(\left[\begin{array}{c}0 \\ 0 \end{array}\right], \left[\begin{array}{cc}\omega_x^2 & \phi \omega_x \omega_y \\ \phi \omega_x \omega_y & \omega_y^2\end{array}\right]\right) \\ 
\left[\begin{array}{c} e^x_{ij} \\ e^y_{ij} \end{array}\right] &\sim N\left(\left[\begin{array}{c}0 \\ 0 \end{array}\right], \left[\begin{array}{cc}\sigma_x^2 & \rho \sigma_x \sigma_y \\ \rho \sigma_x \sigma_y & \sigma_y^2\end{array}\right]\right)
\end{aligned}
$$

and the error terms are mutually independent unless otherwise noted. The raw Pearson's $r$ is calculated using the total sums of squares and cross-products:

$$
r = \frac{SS_{xy}}{\sqrt{SS_{xx} SS_{yy}}},
$$

where 

$$
\begin{aligned}
SS_{xx} &= \sum_{j=1}^m \sum_{i=1}^{n_j} \left(X_{ij} - \bar{\bar{x}}\right)^2, \qquad \bar{\bar{x}} = \frac{1}{N} \sum_{j=1}^m \sum_{i=1}^{n_j} X_{ij} \\
SS_{xy} &= \sum_{j=1}^m \sum_{i=1}^{n_j} \left(Y_{ij} - \bar{\bar{y}}\right)^2, \qquad \bar{\bar{y}} = \frac{1}{N} \sum_{j=1}^m \sum_{i=1}^{n_j} Y_{ij} \\
SS_{xy} &= \sum_{j=1}^m \sum_{i=1}^{n_j} \left(X_{ij} - \bar{\bar{x}}\right) \left(Y_{ij} - \bar{\bar{y}}\right).
\end{aligned}
$$

### Common correlation and ICC 

The distribution of the total correlation seems to be pretty complicated. So far, I've been able to obtain the variance of $r$ for a special case that makes some further, fairly restrictive assumptions. Specifically, assume that the correlation is constant across the two levels, so that $\phi = \rho$, and that the intra-class correlation of $X$ is the same as that of $Y$. Let $k = \omega_x^2 / \sigma_x^2 = \omega_y^2 / \sigma_y^2$. Then 

$$
\text{Var}(r) \approx \frac{(1 - \rho^2)^2}{\tilde{N}},
$$

where 

$$
\tilde{N} = \frac{[f_1 k + N - 1]^2}{f_2 k^2 + 2 f_1 k + N - 1},
$$

$\displaystyle{f_1 = N - \frac{1}{N}\sum_{j=1}^m n_j^2}$, and $\displaystyle{f_2 = \sum_{j=1}^m n_j^2 - \frac{2}{N}\sum_{j=1}^m n_j^3 + \frac{1}{N^2} \left(\sum_{j=1}^m n_j^2 \right)^2}$.

If the clusters are all of equal size $n$, then 

$$
\tilde{N} = \frac{[n(m - 1)k + nm - 1]^2}{n^2 (m - 1) k^2 + 2 n (m - 1)k + nm - 1}.
$$

Under the (restrictive) assumptions of common correlation and equal ICCs, Fisher's z transformation is variance-stabilizing (as it is under simple random sampling), so it seems reasonable to use

$$
\text{Var}\left(z(r)\right) \approx \frac{1}{\tilde{N} - 3}.
$$

```{r}
library(purrr)
library(dplyr)
library(ggplot2)

deff <- function(icc, n, m = length(n)) {
  k <- icc / (1 - icc)
  if (length(n) == 1) n <- rep(n, m)
  N <- sum(n)
  n_sq <- sum(n^2)
  f1 <- N - n_sq / N
  f2 <- n_sq - 2 * sum(n^3) / N + n_sq^2 / N^2
  N_tilde <- (f1 * k + N - 1)^2 / (f2 * k^2 + 2 * f1 * k + N - 1)
  (N - 1) / N_tilde
}

deffs <- 
  list(
    icc = c(0, 0.05, seq(0.1, 0.4, 0.1)),
    n = c(1, seq(5, 50, 5)),
    m = c(5, seq(10, 50, 10))
  ) %>%
  cross_df() %>%
  group_by_all() %>%
  mutate(
    deff = deff(icc, n, m),
    def2 = (n - 1) * icc + 1
  )

ggplot(deffs) + 
  geom_line(aes(n, deff, color = factor(icc))) + 
  coord_cartesian(ylim = c(0,5)) + 
  facet_wrap(~ m, labeller = "label_both") + 
  theme_light() + 
  labs(color = "ICC")

```


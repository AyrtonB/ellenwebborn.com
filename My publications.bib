
@article{pustejovsky_four_2015,
	title = {Four {Methods} for {Analyzing} {Partial} {Interval} {Recording} {Data}, with {Application} to {Single}-{Case} {Research}},
	volume = {50},
	copyright = {All rights reserved},
	issn = {0027-3171, 1532-7906},
	url = {http://www.tandfonline.com/doi/full/10.1080/00273171.2015.1014879},
	doi = {10.1080/00273171.2015.1014879},
	language = {en},
	number = {3},
	urldate = {2018-11-30},
	journal = {Multivariate Behavioral Research},
	author = {Pustejovsky, James E. and Swan, Daniel M.},
	month = may,
	year = {2015},
	pages = {365--380},
	file = {Pustejovsky & Swan (2015).pdf:C\:\\Users\\jep2963\\Box Sync\\Library\\Library\\Pustejovsky & Swan (2015).pdf:application/pdf}
}

@article{pustejovsky_alternating_2014,
	title = {Alternating {Renewal} {Process} {Models} for {Behavioral} {Observation}: {Simulation} {Methods}, {Software}, and {Validity} {Illustrations}},
	volume = {39},
	copyright = {All rights reserved},
	issn = {0198-7429, 2163-5307},
	shorttitle = {Alternating {Renewal} {Process} {Models} for {Behavioral} {Observation}},
	url = {http://journals.sagepub.com/doi/10.1177/019874291303900406},
	doi = {10.1177/019874291303900406},
	abstract = {D irect observation recording procedures produce reductive summary measurements o f an underlying stream o f behavior. Previous methodological studies o f these recording procedures have employed simulation methods for generating random behavior streams, many o f which amount to special cases o f a statistical model known as the alternating renewal process. This paper describes the alternating renewal process m odel in its general form, demonstrates how it provides an organizing framework for most past simulation research on direct observation procedures, and introduces a freely available software package that implements the model. The software can be used to simulate behavior streams as w ell as data from many common recording procedures, including continuous recording, momentary time sampling, event counting, and interval recording procedures. Several examples illustrate how the software can be used to study the validity and reliability o f direct observation data and to develop measurement strategies during the planning phases o f em pirical studies.},
	language = {en},
	number = {4},
	urldate = {2018-11-30},
	journal = {Behavioral Disorders},
	author = {Pustejovsky, James E. and Runyon, Christopher},
	month = aug,
	year = {2014},
	pages = {211--227},
	file = {Pustejovsky & Runyon (2014).pdf:C\:\\Users\\jep2963\\Box Sync\\Library\\Library\\Pustejovsky & Runyon (2014).pdf:application/pdf}
}

@article{pustejovsky_using_2018,
	title = {Using response ratios for meta-analyzing single-case designs with behavioral outcomes},
	volume = {68},
	copyright = {All rights reserved},
	issn = {00224405},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022440518300232},
	doi = {10.1016/j.jsp.2018.02.003},
	abstract = {Methods for meta-analyzing single-case designs (SCDs) are needed to inform evidence-based practice in clinical and school settings and to draw broader and more defensible generalizations in areas where SCDs comprise a large part of the research base. The most widely used outcomes in single-case research are measures of behavior collected using systematic direct observation, which typically take the form of rates or proportions. For studies that use such measures, one simple and intuitive way to quantify eﬀect sizes is in terms of proportionate change from baseline, using an eﬀect size known as the log response ratio. This paper describes methods for estimating log response ratios and combining the estimates using meta-analysis. The methods are based on a simple model for comparing two phases, where the level of the outcome is stable within each phase and the repeated outcome measurements are independent. Although autocorrelation will lead to biased estimates of the sampling variance of the eﬀect size, meta-analysis of response ratios can be conducted with robust variance estimation procedures that remain valid even when sampling variance estimates are biased. The methods are demonstrated using data from a recent meta-analysis on group contingency interventions for student problem behavior.},
	language = {en},
	urldate = {2018-11-30},
	journal = {Journal of School Psychology},
	author = {Pustejovsky, James E.},
	month = jun,
	year = {2018},
	pages = {99--112},
	file = {Pustejovsky (2018) Using LRRs.pdf:C\:\\Users\\jep2963\\Box Sync\\Library\\Library\\Pustejovsky (2018) Using LRRs.pdf:application/pdf}
}

@article{pustejovsky_measurement-comparable_2015,
	title = {Measurement-comparable effect sizes for single-case studies of free-operant behavior.},
	volume = {20},
	copyright = {All rights reserved},
	issn = {1939-1463, 1082-989X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000019},
	doi = {10.1037/met0000019},
	abstract = {Single-case research comprises a set of designs and methods for evaluating the effects of interventions, practices, or programs on individual cases, through comparison of outcomes measured at different points in time. Although there has long been interest in meta-analytic techniques for synthesizing single-case research, there has been little scrutiny of whether proposed effect sizes remain on a directly comparable metric when outcomes are measured using different operational procedures. Much of single-case research focuses on behavioral outcomes in free-operant contexts, which may be measured using a variety of different direct observation procedures. This article describes a suite of effect sizes for quantifying changes in free-operant behavior, motivated by an alternating renewal process model that allows measurement comparability to be established in precise terms. These effect size metrics have the advantage of comporting with how direct observation data are actually collected and summarized. Effect size estimators are proposed that are applicable when the behavior being measured remains stable within a given treatment condition. The methods are illustrated by 2 examples, including a re-analysis of a systematic review of the effects of choice-making opportunities on problem behavior.},
	language = {en},
	number = {3},
	urldate = {2018-11-30},
	journal = {Psychological Methods},
	author = {Pustejovsky, James E.},
	year = {2015},
	keywords = {10, 1037, alternating renewal process, doi, dx, effect size, free-operant behavior, http, met0000019, org, single-case research, supp, supplemental materials},
	pages = {342--359},
	file = {Pustejovsky (2015) - Measurement-comparable effect sizes for single-case studies of free operant behavior.pdf:C\:\\Users\\jep2963\\Box Sync\\Library\\Library\\Pustejovsky (2015) - Measurement-comparable effect sizes for single-case studies of free operant behavior.pdf:application/pdf}
}

@article{pustejovsky_converting_2014,
	title = {Converting from d to r to z when the design uses extreme groups, dichotomization, or experimental control.},
	volume = {19},
	copyright = {All rights reserved},
	issn = {1939-1463, 1082-989X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0033788},
	doi = {10.1037/a0033788},
	abstract = {Meta-analyses of the relationship between 2 continuous variables sometimes involves conversions between different effect sizes, but methodological literature offers conflicting guidance about how to make such conversions. This article provides methods for converting from a standardized mean difference to a correlation coefficient (and from there to Fisher’s z) under 3 types of study designs: extreme groups, dichotomization of a continuous variable, and controlled experiments. Also provided are formulas and recommendations regarding how the sampling variance of effect size statistics should be estimated in each of these cases. The conversion formula for extreme groups designs, originally due to Feldt (1961), can be viewed as a generalization of Hunter and Schmidt’s (1990) method for dichotomization designs. A simulation study examines the finite-sample properties of the proposed methods. The conclusion highlights areas where current guidance in the literature should be amended or clarified.},
	language = {en},
	number = {1},
	urldate = {2018-11-30},
	journal = {Psychological Methods},
	author = {Pustejovsky, James E.},
	year = {2014},
	pages = {92--112},
	file = {Pustejovsky (2014) d-to-r-to-z.pdf:C\:\\Users\\jep2963\\Box Sync\\Library\\Library\\Pustejovsky (2014) d-to-r-to-z.pdf:application/pdf}
}

@article{pustejovsky_testing_2018,
	title = {Testing for funnel plot asymmetry of standardized mean differences},
	copyright = {All rights reserved},
	issn = {17592879},
	url = {http://doi.wiley.com/10.1002/jrsm.1332},
	doi = {10.1002/jrsm.1332},
	language = {en},
	urldate = {2019-01-07},
	journal = {Research Synthesis Methods},
	author = {Pustejovsky, James E. and Rodgers, Melissa},
	month = dec,
	year = {2018}
}

@incollection{pustejovsky_research_2017,
	address = {New York, NY},
	edition = {2nd Edition},
	title = {Research {Synthesis} and {Meta}-{Analysis} of {Single}-{Case} {Designs}},
	copyright = {All rights reserved},
	language = {en},
	booktitle = {Handbook of {Special} {Education}},
	publisher = {Routledge},
	author = {Pustejovsky, James E and Ferron, John},
	year = {2017},
	pages = {63},
	file = {Pustejovsky-Ferron-2017-Research-synthesis-and-meta-analysis-of-SCDs.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\A7ADA4T5\\Pustejovsky-Ferron-2017-Research-synthesis-and-meta-analysis-of-SCDs.pdf:application/pdf}
}

@book{pustejovsky_singlecasees:_2018,
	title = {{SingleCaseES}: {A} {Calculator} for {Single}-{Case} {Effect} {Sizes}},
	copyright = {All rights reserved},
	url = {https://github.com/jepusto/SingleCaseES},
	author = {Pustejovsky, James E. and Swan, Daniel M.},
	year = {2018},
	annote = {R package version 0.4.0.9999}
}

@article{pustejovsky_procedural_2019,
	title = {Procedural sensitivities of effect sizes for single-case designs with directly observed behavioral outcome measures.},
	volume = {24},
	copyright = {All rights reserved},
	issn = {1939-1463, 1082-989X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000179},
	doi = {10.1037/met0000179},
	language = {en},
	number = {2},
	urldate = {2018-11-30},
	journal = {Psychological Methods},
	author = {Pustejovsky, James E.},
	year = {2019},
	pages = {217--235},
	file = {Pustejovsky (2018) procedural sensitivities.pdf:C\:\\Users\\jep2963\\Box Sync\\Library\\Library\\Pustejovsky (2018) procedural sensitivities.pdf:application/pdf}
}

@article{pustejovsky_small-sample_2018,
	title = {Small-{Sample} {Methods} for {Cluster}-{Robust} {Variance} {Estimation} and {Hypothesis} {Testing} in {Fixed} {Effects} {Models}},
	volume = {36},
	copyright = {All rights reserved},
	issn = {0735-0015, 1537-2707},
	url = {https://www.tandfonline.com/doi/full/10.1080/07350015.2016.1247004},
	doi = {10.1080/07350015.2016.1247004},
	language = {en},
	number = {4},
	urldate = {2018-11-30},
	journal = {Journal of Business \& Economic Statistics},
	author = {Pustejovsky, James E. and Tipton, Elizabeth},
	month = oct,
	year = {2018},
	pages = {672--683},
	file = {Pustejovsky & Tipton (2018).pdf:C\:\\Users\\jep2963\\Box Sync\\Library\\Library\\Pustejovsky & Tipton (2018).pdf:application/pdf}
}

@article{Shadish2013d,
	title = {Analysis and meta-analysis of single-case designs with a standardized mean difference statistic: {A} primer and applications},
	volume = {52},
	copyright = {All rights reserved},
	issn = {0022-4405},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0022440513001076},
	doi = {10.1016/j.jsp.2013.11.005},
	number = {2},
	journal = {Journal of School Psychology},
	author = {Shadish, William R and Hedges, Larry V and Pustejovsky, James E},
	month = dec,
	year = {2014},
	note = {tex.publisher: Elsevier B.V.},
	keywords = {Analysis, d-Statistic, Meta-analysis, Single case designs},
	pages = {123--147}
}

@article{Pustejovsky2014design,
	title = {Design-comparable effect sizes in multiple baseline designs: {A} general modeling framework},
	volume = {39},
	copyright = {All rights reserved},
	issn = {1076-9986},
	doi = {10.3102/1076998614547577},
	abstract = {© 2014 AERA. In single-case research, the multiple baseline design is a widely used approach for evaluating the effects of interventions on individuals. Multiple baseline designs involve repeated measurement of outcomes over time and the controlled introduction of a treatment at different times for different individuals. This article outlines a general framework for defining effect sizes in multiple baseline designs that are directly comparable to the standardized mean difference from a between-subjects randomized experiment. The target, design-comparable effect size parameter can be estimated using restricted maximum likelihood together with a small sample correction analogous to Hedges's g. The approach is demonstrated using hierarchical linear models that include baseline time trends and treatment-by-time interactions. A simulation compares the performance of the proposed estimator to that of an alternative, and an application illustrates the model-fitting process.},
	number = {5},
	journal = {Journal of Educational and Behavioral Statistics},
	author = {Pustejovsky, James E and Hedges, Larry V and Shadish, William R},
	year = {2014},
	keywords = {Effect size, Hierarchical linear model, Single-case research},
	pages = {368--393}
}

@article{Hedges2012MB,
	title = {A standardized mean difference effect size for multiple baseline designs across individuals},
	copyright = {All rights reserved},
	issn = {17592879},
	doi = {10.1002/jrsm.1086},
	journal = {Research Synthesis Methods},
	author = {Hedges, Larry V and Pustejovsky, James E and Shadish, William R},
	month = aug,
	year = {2013},
	note = {tex.institution: Northwestern University
tex.location: Evanston, IL},
	keywords = {as a tool for, class of research methods, different conditions to the, effect size, evaluating interventions, hierarchical linear model, involving deliberate assignment of, multiple baseline designs, of one or more, outcomes over time, same individual and measurement, single-case design, single-case designs are a, these}
}

@article{Hedges2012ABk,
	title = {A standardized mean difference effect size for single case designs},
	volume = {3},
	copyright = {All rights reserved},
	issn = {17592879},
	doi = {10.1002/jrsm.1052},
	journal = {Research Synthesis Methods},
	author = {Hedges, Larry V and Pustejovsky, James E and Shadish, William R},
	year = {2012},
	keywords = {autocorrelation, broader category of repeated, distinguished by the fact, effect size, hierarchical linear model, individual and, measure an outcome over, measures, single case designs, single case designs are, special type of the, such designs are a, that they assign different, time, treatments to the same},
	pages = {224--239}
}

@article{zimmerman_single-case_2018,
	title = {Single-case synthesis tools {II}: {Comparing} quantitative outcome measures},
	volume = {79},
	copyright = {All rights reserved},
	issn = {08914222},
	shorttitle = {Single-case synthesis tools {II}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0891422218300283},
	doi = {10.1016/j.ridd.2018.02.001},
	abstract = {Varying methods for evaluating the outcomes of single case research designs (SCD) are currently used in reviews and meta-analyses of interventions. Quantitative eﬀect size measures are often presented alongside visual analysis conclusions. Six measures across two classes—overlap measures (percentage non-overlapping data, improvement rate diﬀerence, and Tau) and parametric within-case eﬀect sizes (standardized mean diﬀerence and log response ratio [increasing and decreasing])—were compared to determine if choice of synthesis method within and across classes impacts conclusions regarding eﬀectiveness. The eﬀectiveness of sensory-based interventions (SBI), a commonly used class of treatments for young children, was evaluated. Separately from evaluations of rigor and quality, authors evaluated behavior change between baseline and SBI conditions. SBI were unlikely to result in positive behavior change across all measures except IRD. However, subgroup analyses resulted in variable conclusions, indicating that the choice of measures for SCD meta-analyses can impact conclusions. Suggestions for using the log response ratio in SCD meta-analyses and considerations for understanding variability in SCD meta-analysis conclusions are discussed.},
	language = {en},
	urldate = {2019-01-11},
	journal = {Research in Developmental Disabilities},
	author = {Zimmerman, Kathleen N. and Pustejovsky, James E. and Ledford, Jennifer R. and Barton, Erin E. and Severini, Katherine E. and Lloyd, Blair P.},
	month = aug,
	year = {2018},
	pages = {65--76},
	file = {Zimmerman et al. (2018) Tools Part II.pdf:C\:\\Users\\jep2963\\Box Sync\\Library\\Library\\Zimmerman et al. (2018) Tools Part II.pdf:application/pdf}
}

@article{zimmerman_single-case_2018-1,
	title = {Single-case synthesis tools {I}: {Comparing} tools to evaluate {SCD} quality and rigor},
	volume = {79},
	copyright = {All rights reserved},
	issn = {08914222},
	shorttitle = {Single-case synthesis tools {I}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0891422218300301},
	doi = {10.1016/j.ridd.2018.02.003},
	abstract = {Tools for evaluating the quality and rigor of single case research designs (SCD) are often used when conducting SCD syntheses. Preferred components include evaluations of design features related to the internal validity of SCD to obtain quality and/or rigor ratings. Three tools for evaluating the quality and rigor of SCD (Council for Exceptional Children, What Works Clearinghouse, and Single-Case Analysis and Design Framework) were compared to determine if conclusions regarding the eﬀectiveness of antecedent sensory-based interventions for young children changed based on choice of quality evaluation tool. Evaluation of SCD quality diﬀered across tools, suggesting selection of quality evaluation tools impacts evaluation ﬁndings. Suggestions for selecting an appropriate quality and rigor assessment tool are provided and across-tool conclusions are drawn regarding the quality and rigor of studies. Finally, authors provide guidance for using quality evaluations in conjunction with outcome analyses when conducting syntheses of interventions evaluated in the context of SCD.},
	language = {en},
	urldate = {2019-01-11},
	journal = {Research in Developmental Disabilities},
	author = {Zimmerman, Kathleen N. and Ledford, Jennifer R. and Severini, Katherine E. and Pustejovsky, James E. and Barton, Erin E. and Lloyd, Blair P.},
	month = aug,
	year = {2018},
	pages = {19--32},
	file = {Zimmerman et al. (2018) Tools Part I.pdf:C\:\\Users\\jep2963\\Box Sync\\Library\\Library\\Zimmerman et al. (2018) Tools Part I.pdf:application/pdf}
}

@article{odom_between-case_2018,
	title = {Between-case standardized effect size analysis of single case designs: {Examination} of the two methods},
	volume = {79},
	copyright = {All rights reserved},
	issn = {08914222},
	shorttitle = {Between-case standardized effect size analysis of single case designs},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0891422218301227},
	doi = {10.1016/j.ridd.2018.05.009},
	abstract = {An increasing movement in single case research is to employ statistical analyses as one form of data analysis. Researchers have proposed diﬀerent statistical approaches. The purpose of this paper is to examine the utility and discriminant validity of two novel types of between-case standardized eﬀect size analyses with two existing systematic reviews. The between-case analyses found greater eﬀect sizes for the studies in the object play review and smaller eﬀect sizes for studies of sensory intervention, which were consistent with the overall conclusions reached in the original systematic reviews. These ﬁndings provide evidence of discriminant validity, although concerns remain around the methods’ utility across diﬀerent single case research designs. Future directions for research and development also are provided.},
	language = {en},
	urldate = {2019-01-11},
	journal = {Research in Developmental Disabilities},
	author = {Odom, Samuel L. and Barton, Erin E. and Reichow, Brian and Swaminathan, Hariharan and Pustejovsky, James E.},
	month = aug,
	year = {2018},
	note = {Citation Key Alias: odom2018BetweencaseStandardizedEffecta},
	pages = {88--96},
	file = {Odom et al. (2018).pdf:C\:\\Users\\jep2963\\Box Sync\\Library\\Library\\Odom et al. (2018).pdf:application/pdf;Odom et al. (2018).pdf:C\:\\Users\\jep2963\\Zotero\\storage\\57UZQ8XP\\Odom et al. (2018).pdf:application/pdf}
}

@article{Common2017,
	title = {Functional assessment-based interventions for students with or at-risk for high-incidence disabilities: {Field} testing single-case synthesis methods},
	volume = {38},
	copyright = {All rights reserved},
	issn = {0741-9325},
	doi = {10.1177/0741932517693320},
	abstract = {© 2017, © Hammill Institute on Disabilities 2017. This systematic review investigated one systematic approach to designing, implementing, and evaluating functional assessment–based interventions (FABI) for use in supporting school-age students with or at-risk for high-incidence disabilities. We field tested several recently developed methods for single-case design syntheses. First, we appraised the quality of individual studies and the overall body of work using Council for Exceptional Children's standards. Next, we calculated and meta-analyzed within-case and between-case effect sizes. Results indicated that studies were of high methodological quality, with nine studies identified as being methodologically sound and demonstrating positive outcomes across 14 participants. However, insufficient evidence was available to classify the evidence base for FABIs due to small number of participants within (fewer than recommended three) and across (fewer than recommended 20) studies. Nonetheless, average within-case effect sizes were equivalent to increases of 118\% between baseline and intervention phases. Finally, potential moderating variables were examined. Limitations and future directions are discussed.},
	number = {6},
	journal = {Remedial and Special Education},
	author = {Common, Eric Alan and Lane, Kathleen Lynne and Pustejovsky, James E and Johnson, Austin H. and Johl, Liane Elizabeth},
	month = nov,
	year = {2017},
	keywords = {behavior intervention plan, effect size, evidence-based practice, functional behavior assessment, quality indicator, Tier 3},
	pages = {331--352}
}

@article{Maggin2017meta-analysis,
	title = {A meta-analysis of school-based group contingency interventions for students with challenging behavior: {An} update},
	volume = {38},
	copyright = {All rights reserved},
	issn = {0741-9325},
	doi = {10.1177/0741932517716900},
	abstract = {© 2017, © Hammill Institute on Disabilities 2017. Group contingencies are recognized as a potent intervention for addressing challenging student behavior in the classroom, with research reviews supporting the use of this intervention platform going back more than four decades. Over this time period, the field of education has increasingly emphasized the role of research evidence for informing practice, as reflected in the increased use of systematic reviews and meta-analyses. In the current article, we continue this trend by applying recently developed between-case effect size measures and transparent visual analysis procedures to synthesize an up-to-date set of group contingency studies that used single-case designs. Results corroborated recent systematic reviews by indicating that group contingencies are generally effective—particularly for addressing challenging behavior in general education classrooms. However, our review highlights the need for more research on students with disabilities and the need to collect and report information about participants' functional level.},
	number = {6},
	journal = {Remedial and Special Education},
	author = {Maggin, Daniel M and Pustejovsky, James E and Johnson, A.H. Austin H},
	month = nov,
	year = {2017},
	keywords = {behavior, evidence-based practice, management, meta-analysis, research methodology, single-subject},
	pages = {353--370}
}

@unpublished{Pustejovsky2013observation,
	title = {Observation procedures and {Markov} chain models for estimating the prevalence and incidence of a behavior},
	copyright = {All rights reserved},
	author = {Pustejovsky, James E},
	year = {2013},
	note = {tex.publisher: Poster presented at the annual meeting of the American Educational Research Association, San Francisco, CA}
}

@article{Pustejovsky2014ARPobservation,
	title = {{ARPobservation}: {Simulating} recording procedures for direct observation of behavior},
	copyright = {All rights reserved},
	url = {http://cran.r-project.org/web/packages/ARPobservation},
	author = {Pustejovsky, James E},
	year = {2014},
	note = {tex.publisher: R package Version 1.0}
}

@incollection{Shadish2012analyzing,
	address = {Washington, DC},
	title = {Analyzing single-case designs: d, {G}, hierarchical models, {Bayesian} estimators, generalized additive models, and the hopes and fears of researchers about analyses},
	copyright = {All rights reserved},
	booktitle = {Single-{Case} {Intervention} {Research}: {Methodological} and {Statistical} {Advances}},
	publisher = {American Psychological Association},
	author = {Shadish, William R and Hedges, Larry V and Pustejovsky, James E and Rindskopf, David M and Boyajian, Jonathan G. and Sullivan, Kristynn J},
	editor = {Kratochwill, Thomas R and Levin, Joel R},
	year = {2014},
	note = {tex.chapter: 8},
	pages = {247--281}
}

@phdthesis{Pustejovsky2013operationally,
	title = {Operationally comparable effect sizes for meta-analysis of single-case research},
	copyright = {All rights reserved},
	school = {Northwestern University},
	author = {Pustejovsky, James E},
	year = {2013}
}

@article{swan_gradual_2018,
	title = {A gradual effects model for single-case designs},
	volume = {53},
	copyright = {All rights reserved},
	issn = {0027-3171, 1532-7906},
	url = {https://www.tandfonline.com/doi/full/10.1080/00273171.2018.1466681},
	doi = {10.1080/00273171.2018.1466681},
	abstract = {Single-case designs are a class of repeated measures experiments used to evaluate the effects of interventions for small or specialized populations, such as individuals with low-incidence disabilities. There has been growing interest in systematic reviews and syntheses of evidence from single-case designs, but there remains a need to further develop appropriate statistical models and effect sizes for data from the designs. We propose a novel model for single-case data that exhibit nonlinear time trends created by an intervention that produces gradual effects, which build up and dissipate over time. The model expresses a structural relationship between a pattern of treatment assignment and an outcome variable, making it appropriate for both treatment reversal and multiple baseline designs. It is formulated as a generalized linear model so that it can be applied to outcomes measured as frequency counts or proportions, both of which are commonly used in single-case research, while providing readily interpretable effect size estimates such as log response ratios or log odds ratios. We demonstrate the gradual effects model by applying it to data from a single-case study and examine the performance of proposed estimation methods in a Monte Carlo simulation of frequency count data.},
	language = {en},
	number = {4},
	urldate = {2019-01-25},
	journal = {Multivariate Behavioral Research},
	author = {Swan, Daniel M. and Pustejovsky, James E.},
	month = jul,
	year = {2018},
	pages = {574--593},
	file = {Swan & Pustejovsky (2018) GEM.pdf:C\:\\Users\\jep2963\\Box Sync\\Library\\Library\\Swan & Pustejovsky (2018) GEM.pdf:application/pdf}
}

@techreport{ledford_systematic_2019,
	type = {preprint},
	title = {Systematic {Review} and {Meta}-{Analysis} of {Stay}-{Play}-{Talk} {Interventions} for {Improving} {Social} {Behaviors} of {Young} {Children}},
	copyright = {All rights reserved},
	url = {https://osf.io/u7cph},
	abstract = {Stay-play-talk (SPT) is a peer-mediated intervention which involves training peer implementers to stay in proximity to, play with, and talk to a focal child who has disabilities or lower social competence. This systematic review and meta-analysis investigated the contexts in which SPT interventions have been conducted, the methodological adequacy of the research assessing its effects, and the outcomes for both peer implementers and focal children. Studies have primarily occurred in inclusive preschool settings during free play activities, with researchers serving as facilitators. Average effects were positive for both peer implementers and focal children, although considerable heterogeneity across studies was observed. Additional research is needed to determine what peer implementer and focal child characteristics moderate intervention success, what modifications are needed for children who have complex communication needs, and optimal procedural variations (e.g., group size, training time).},
	urldate = {2019-06-20},
	institution = {Open Science Framework},
	author = {Ledford, Jennifer R. and Pustejovsky, James E},
	month = jun,
	year = {2019},
	doi = {10.31219/osf.io/u7cph}
}

@article{barton_technology-aided_2017,
	title = {Technology-{Aided} {Instruction} and {Intervention} for {Students} {With} {ASD}: {A} {Meta}-{Analysis} {Using} {Novel} {Methods} of {Estimating} {Effect} {Sizes} for {Single}-{Case} {Research}},
	volume = {38},
	copyright = {All rights reserved},
	issn = {0741-9325, 1538-4756},
	shorttitle = {Technology-{Aided} {Instruction} and {Intervention} for {Students} {With} {ASD}},
	url = {http://journals.sagepub.com/doi/10.1177/0741932517729508},
	doi = {10.1177/0741932517729508},
	abstract = {The adoption of methods and strategies validated through rigorous, experimentally oriented research is a core professional value of special education. We conducted a systematic review and meta-analysis examining the experimental literature on Technology-Aided Instruction and Intervention (TAII) using research identified as part of the National Autism Professional Development Project. We applied novel between-case effect size methods to the TAII single-case research base. In addition, we used meta-analytic methodologies to examine the methodological quality of the research, calculate average effect sizes to quantify the level of evidence for TAII, and compare effect sizes across single-case and group-based experimental research. Results identified one category of TAII—computer-assisted instruction—as an evidence-based practice across both single-case and group studies. The remaining two categories of TAII—augmentative and alternative communication and virtual reality—were not identified as evidence-based using What Works Clearinghouse summary ratings.},
	language = {en},
	number = {6},
	urldate = {2019-08-09},
	journal = {Remedial and Special Education},
	author = {Barton, Erin E. and Pustejovsky, James E. and Maggin, Daniel M. and Reichow, Brian},
	month = nov,
	year = {2017},
	pages = {371--386},
	file = {Barton et al. (2017).pdf:C\:\\Users\\jep2963\\Zotero\\storage\\5VSYR7KH\\Barton et al. (2017).pdf:application/pdf}
}

@article{pustejovsky_examination_2019,
	title = {An {Examination} of {Measurement} {Procedures} and {Characteristics} of {Baseline} {Outcome} {Data} in {Single}-{Case} {Research}},
	copyright = {All rights reserved},
	language = {en},
	journal = {Behavior Modification},
	author = {Pustejovsky, James E and Swan, Daniel M and English, Kyle W},
	year = {2019},
	pages = {32},
	file = {Pustejovsky, Swan, & English (2019).pdf:C\:\\Users\\jep2963\\Zotero\\storage\\MSERW9L8\\Pustejovsky, Swan, & English (2019).pdf:application/pdf}
}

@article{maggin_introduction_2017,
	title = {Introduction to the {Special} {Issue} on {Single}-{Case} {Systematic} {Reviews} and {Meta}-{Analyses}},
	volume = {38},
	copyright = {All rights reserved},
	issn = {0741-9325, 1538-4756},
	url = {http://journals.sagepub.com/doi/10.1177/0741932517717043},
	doi = {10.1177/0741932517717043},
	abstract = {This special issue provides an update on recent conceptual and methodological developments for conducting systematic reviews and meta-analyses of single-case research. In this introductory article, we (a) describe the important role of systematic reviews and meta-analyses within special education; (b) discuss several methodological issues authors must consider when planning and conducting a rigorous single-case review; and (c) summarize current approaches for addressing each of these issues. Following this overview, we describe each article in the special issue, paying particular attention to the methodological areas highlighted. We conclude with recommendations for continued research and development in several areas.},
	language = {en},
	number = {6},
	urldate = {2019-08-08},
	journal = {Remedial and Special Education},
	author = {Maggin, Daniel M. and Lane, Kathleen Lynne and Pustejovsky, James E.},
	month = nov,
	year = {2017},
	pages = {323--330},
	file = {Maggin, Lane, & Pustejovsky (2017) - RASE intro.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\2YK33XCW\\Maggin, Lane, & Pustejovsky (2017) - RASE intro.pdf:application/pdf}
}

@article{tipton_small-sample_2015,
	title = {Small-sample adjustments for tests of moderators and model fit using robust variance estimation in meta-regression},
	volume = {40},
	copyright = {All rights reserved},
	issn = {1076-9986, 1935-1054},
	url = {http://journals.sagepub.com/doi/10.3102/1076998615606099},
	doi = {10.3102/1076998615606099},
	language = {en},
	number = {6},
	urldate = {2019-08-14},
	journal = {Journal of Educational and Behavioral Statistics},
	author = {Tipton, Elizabeth and Pustejovsky, James E.},
	month = dec,
	year = {2015},
	pages = {604--634},
	file = {Tipton and Pustejovsky - 2015 - Small-Sample Adjustments for Tests of Moderators a.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\LEW5XRIQ\\Tipton and Pustejovsky - 2015 - Small-Sample Adjustments for Tests of Moderators a.pdf:application/pdf}
}

@article{tipton_history_2019,
	title = {A history of meta-regression: {Technical}, conceptual, and practical developments between 1974 and 2018},
	volume = {10},
	copyright = {All rights reserved},
	issn = {17592879},
	shorttitle = {A history of meta-regression},
	url = {http://doi.wiley.com/10.1002/jrsm.1338},
	doi = {10.1002/jrsm.1338},
	language = {en},
	number = {2},
	urldate = {2019-08-14},
	journal = {Research Synthesis Methods},
	author = {Tipton, Elizabeth and Pustejovsky, James E. and Ahmadi, Hedyeh},
	month = jun,
	year = {2019},
	pages = {161--179},
	file = {Tipton et al. - 2019 - A history of meta-regression Technical, conceptua.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\2QRHX7EW\\Tipton et al. - 2019 - A history of meta-regression Technical, conceptua.pdf:application/pdf}
}

@article{tipton_current_2019,
	title = {Current practices in meta-regression in psychology, education, and medicine},
	volume = {10},
	copyright = {All rights reserved},
	issn = {17592879},
	url = {http://doi.wiley.com/10.1002/jrsm.1339},
	doi = {10.1002/jrsm.1339},
	language = {en},
	number = {2},
	urldate = {2019-08-14},
	journal = {Research Synthesis Methods},
	author = {Tipton, Elizabeth and Pustejovsky, James E. and Ahmadi, Hedyeh},
	month = jun,
	year = {2019},
	pages = {180--194},
	file = {Tipton et al. - 2019 - Current practices in meta-regression in psychology.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\UFZKCHXM\\Tipton et al. - 2019 - Current practices in meta-regression in psychology.pdf:application/pdf}
}

@article{wahman_examining_2019,
	title = {Examining the {Effects} of {Social} {Stories}™ on {Challenging} {Behavior} and {Prosocial} {Skills} in {Young} {Children}: {A} {Systematic} {Review} and {Meta}-{Analysis}},
	copyright = {All rights reserved},
	abstract = {Social stories are a commonly used intervention practice in early childhood special education. Recent systematic reviews have documented the evidence base for social stories, but findings are mixed. We examined the efficacy of social stories for young children (i.e., 3–5 years) with challenging behavior across 12 single-case studies, which included 30 participants. The What Works Clearinghouse standards for single-case research design were used to evaluate the rigor of studies that included social stories as a primary intervention. For studies meeting standards, we synthesized findings on the efficacy of social stories using meta-analysis techniques and a parametric effect size measure, the log response ratio. Trends in participants’ response to treatment were also explored. Results indicate variability in rigor and efficacy for the use of social stories as an isolated intervention and in combination with other intervention approaches. Additional studies that investigate the efficacy of social stories as a primary intervention are warranted.},
	language = {en},
	journal = {Topics in Early Childhood Special Education},
	author = {Wahman, Charis L and Pustejovsky, James E. and Ostrosky, Michaelene and Santos, Rosa Milagros},
	year = {2019},
	pages = {13},
	file = {Wahman - Examining the Effects of Social Stories™ on Challe.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\MVP8JL5A\\Wahman - Examining the Effects of Social Stories™ on Challe.pdf:application/pdf}
}

@article{swan_impact_2020,
	title = {The impact of response-guided designs on count outcomes in single-case experimental design baselines},
	copyright = {All rights reserved},
	issn = {1748-9539, 1748-9547},
	url = {https://www.tandfonline.com/doi/full/10.1080/17489539.2020.1739048},
	doi = {10.1080/17489539.2020.1739048},
	abstract = {In single-case experimental design (SCED) research, researchers often choose when to start treatment based on whether the baseline data collected so far are stable, using what is called a response-guided design. There is evidence that response-guided designs are common, and researchers have described a variety of criteria for assessing stability. With many of these criteria, making judgments about stability could yield data with limited variability, which may have consequences for statistical inference and effect size estimates. However, little research has examined the impact of response-guided design on the resulting data. Drawing on both applied and methodological research, we describe several algorithms as models for response-guided design. We use simulation methods to assess how using a response-guided design impacts the baseline data pattern. The simulations generate baseline data in the form of frequency counts, a common type of outcome in SCEDs. Most of the response-guided algorithms we identified lead to baselines with approximately unbiased mean levels, but nearly all of them lead to underestimates in the baseline variance. We discuss implications for the use of response-guided designs in practice and for the plausibility of specific algorithms as representations of actual research practice.},
	language = {en},
	urldate = {2020-04-13},
	journal = {Evidence-Based Communication Assessment and Intervention},
	author = {Swan, Daniel M. and Pustejovsky, James E. and Beretvas, S. Natasha},
	month = mar,
	year = {2020},
	pages = {1--26},
	file = {Swan et al. - 2020 - The impact of response-guided designs on count out.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\DBYVG652\\Swan et al. - 2020 - The impact of response-guided designs on count out.pdf:application/pdf}
}

@article{salsman_psychosocial_2019,
	title = {Psychosocial interventions for cancer survivors: {A} meta-analysis of effects on positive affect},
	volume = {13},
	copyright = {All rights reserved},
	issn = {1932-2259, 1932-2267},
	shorttitle = {Psychosocial interventions for cancer survivors},
	url = {http://link.springer.com/10.1007/s11764-019-00811-8},
	doi = {10.1007/s11764-019-00811-8},
	abstract = {Purpose Positive affect has demonstrated unique benefits in the context of health-related stress and is emerging as an important target for psychosocial interventions. The primary objective of this meta-analysis was to determine whether psychosocial interventions increase positive affect in cancer survivors.
Methods We coded 28 randomized controlled trials of psychosocial interventions assessing 2082 cancer survivors from six electronic databases. We calculated 76 effect sizes for positive affect and conducted synthesis using random effects models with robust variance estimation. Tests for moderation included demographic, clinical, and intervention characteristics.
Results Interventions had a modest effect on positive affect (g = 0.35, 95\% CI [0.16, 0.54]) with substantial heterogeneity of effects across studies (τ{\textasciicircum} ¼ 0:40; I2 = 78\%). Three significant moderators were identified: in-person interventions outperformed remote interventions (P = .046), effects were larger when evaluated against standard of care or wait list control conditions versus attentional, educational, or component controls (P = .009), and trials with survivors of early-stage cancer diagnoses yielded larger effects than those with advancedstage diagnoses (P = .046). We did not detect differential benefits of psychosocial interventions across samples varying in sex, age, ontreatment versus off-treatment status, or cancer type. Although no conclusive evidence suggested outcome reporting biases (P = .370), effects were smaller in studies with lower risk of bias.
Conclusions In-person interventions with survivors of early-stage cancers hold promise for enhancing positive affect, but more methodological rigor is needed. Implications for Cancer Survivors Positive affect strategies can be an explicit target in evidence-based medicine and have a role in patient-centered survivorship care, providing tools to uniquely mobilize human strengths.},
	language = {en},
	number = {6},
	urldate = {2020-04-13},
	journal = {Journal of Cancer Survivorship},
	author = {Salsman, John M. and Pustejovsky, James E. and Schueller, Stephen M. and Hernandez, Rosalba and Berendsen, Mark and McLouth, Laurie E. Steffen and Moskowitz, Judith T.},
	month = dec,
	year = {2019},
	pages = {943--955},
	file = {Salsman et al. - 2019 - Psychosocial interventions for cancer survivors A.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\RV6GDLKM\\Salsman et al. - 2019 - Psychosocial interventions for cancer survivors A.pdf:application/pdf}
}

@article{merluzzi_interventions_2019,
	title = {Interventions to enhance self‐efficacy in cancer patients: {A} meta‐analysis of randomized controlled trials},
	volume = {28},
	copyright = {All rights reserved},
	issn = {1057-9249, 1099-1611},
	shorttitle = {Interventions to enhance self‐efficacy in cancer patients},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pon.5148},
	doi = {10.1002/pon.5148},
	abstract = {Objective: Self‐efficacy expectations are associated with improvements in problematic outcomes widely considered clinically significant (ie, emotional distress, fatigue, and pain), related to positive health behaviors, and as a type of personal agency, inherently valuable. Self‐efficacy expectancies, estimates of confidence to execute behaviors, are important in that changes in self‐efficacy expectations are positively related to future behaviors that promote health and well‐being. The current meta‐analysis investigated the impact of psychological interventions on self‐efficacy expectations for a variety of health behaviors among cancer patients.
Methods: Ovid Medline, PsycINFO, CINAHL, EMBASE, Cochrane Library, and Web of Science were searched with specific search terms for identifying randomized controlled trials (RCTs) that focused on psychologically based interventions. Included studies had (a) an adult cancer sample, (b) a self‐efficacy expectation measure of specific behaviors, and (c) an RCT design. Standard screening and reliability procedures were used for selecting and coding studies. Coding included theoretically informed moderator variables.
Results: Across 79 RCTs, 223 effect sizes, and 8678 participants, the weighted average effect of self‐efficacy expectations was estimated as g = 0.274 (P {\textless} .001). Consistent with the self‐efficacy theory, the average effect for in‐person intervention delivery (g = 0.329) was significantly greater than for all other formats (g = 0.154, P = .023; eg, audiovisual, print, telephone, and Web/internet).
Conclusions: The results establish the impact of psychological interventions on self‐efficacy expectations as comparable in effect size with commonly reported outcomes (distress, fatigue, pain). Additionally, the result that in‐person interventions achieved the largest effect is supported by the social learning theory and could inform research related to the development and evaluation of interventions.},
	language = {en},
	number = {9},
	urldate = {2020-04-13},
	journal = {Psycho-Oncology},
	author = {Merluzzi, Thomas V. and Pustejovsky, James E. and Philip, Errol J. and Sohl, Stephanie J. and Berendsen, Mark and Salsman, John M.},
	month = sep,
	year = {2019},
	pages = {1781--1790},
	file = {Merluzzi et al. - 2019 - Interventions to enhance self‐efficacy in cancer p.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\TBLI8WAF\\Merluzzi et al. - 2019 - Interventions to enhance self‐efficacy in cancer p.pdf:application/pdf}
}

@article{park_effects_2019,
	title = {Effects of psychosocial interventions on meaning and purpose in adults with cancer: {A} systematic review and meta‐analysis},
	volume = {125},
	copyright = {All rights reserved},
	issn = {0008-543X, 1097-0142},
	shorttitle = {Effects of psychosocial interventions on meaning and purpose in adults with cancer},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cncr.32078},
	doi = {10.1002/cncr.32078},
	abstract = {Meaning and purpose in life are associated with the mental and physical health of patients with cancer and survivors and also ­constitute highly valued outcomes in themselves. Because meaning and purpose are often threatened by a cancer diagnosis and treatment, interventions have been developed to promote meaning and purpose. The present meta-analysis of randomized controlled trials (RCTs) evaluated effects of psychosocial interventions on meaning/purpose in adults with cancer and tested potential moderators of intervention effects. Six literature databases were systematically searched to identify RCTs of psychosocial interventions in which meaning or purpose was an outcome. Using Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines, rater pairs extracted and evaluated data for quality. Findings were synthesized across studies with standard meta-analytic methods, including meta-regression with robust variance estimation and risk-of-bias sensitivity analysis. Twenty-nine RCTs were identified, and they encompassed 82 treatment effects among 2305 patients/survivors. Psychosocial interventions were associated with significant improvements in meaning/purpose (g = 0.37; 95\% CI, 0.22-0.52; P {\textless} .0001). Interventions designed to enhance meaning/purpose (g = 0.42; 95\% CI, 0.24-0.60) demonstrated significantly higher effect sizes than those targeting other primary outcomes (g = 0.18; 95\% CI, 0.09-0.27; P = .009). Few other intervention, clinical, or demographic characteristics tested were significant moderators. In conclusion, the results suggest that psychosocial interventions are associated with small to medium effects in enhancing meaning/purpose among patients with cancer, and the benefits are comparable to those of interventions designed to reduce depression, pain, and fatigue in patients with cancer. Methodological concerns include small samples and ambiguity regarding allocation concealment. Future research should focus on explicitly meaning-centered interventions and identify optimal treatment or survivorship phases for implementation. Cancer 2019;125:2383-2393. © 2019 American Cancer Society.},
	language = {en},
	number = {14},
	urldate = {2020-04-13},
	journal = {Cancer},
	author = {Park, Crystal L. and Pustejovsky, James E. and Trevino, Kelly and Sherman, Allen C. and Esposito, Craig and Berendsen, Mark and Salsman, John M.},
	month = jul,
	year = {2019},
	pages = {2383--2393},
	file = {Park et al. - 2019 - Effects of psychosocial interventions on meaning a.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\3IRRQVJF\\Park et al. - 2019 - Effects of psychosocial interventions on meaning a.pdf:application/pdf}
}

@article{jim_religion_2015,
	title = {Religion, spirituality, and physical health in cancer patients: {A} meta-analysis: {Religion}/{Spirituality} and {Physical} {Health}},
	volume = {121},
	copyright = {All rights reserved},
	issn = {0008543X},
	shorttitle = {Religion, spirituality, and physical health in cancer patients},
	url = {http://doi.wiley.com/10.1002/cncr.29353},
	doi = {10.1002/cncr.29353},
	language = {en},
	number = {21},
	urldate = {2020-04-13},
	journal = {Cancer},
	author = {Jim, Heather S. L. and Pustejovsky, James E. and Park, Crystal L. and Danhauer, Suzanne C. and Sherman, Allen C. and Fitchett, George and Merluzzi, Thomas V. and Munoz, Alexis R. and George, Login and Snyder, Mallory A. and Salsman, John M.},
	month = nov,
	year = {2015},
	pages = {3760--3768},
	file = {Jim et al. - 2015 - Religion, spirituality, and physical health in can.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\RCEGIWAI\\Jim et al. - 2015 - Religion, spirituality, and physical health in can.pdf:application/pdf}
}

@article{salsman_meta-analytic_2015,
	title = {A meta-analytic approach to examining the correlation between religion/spirituality and mental health in cancer: {Religion}/{Spirituality} and {Mental} {Health}},
	volume = {121},
	copyright = {All rights reserved},
	issn = {0008543X},
	shorttitle = {A meta-analytic approach to examining the correlation between religion/spirituality and mental health in cancer},
	url = {http://doi.wiley.com/10.1002/cncr.29350},
	doi = {10.1002/cncr.29350},
	abstract = {Religion and spirituality (R/S) are patient-centered factors and often are resources for managing the emotional sequelae of the cancer experience. Studies investigating the correlation between R/S (eg, beliefs, experiences, coping) and mental health (eg, depression, anxiety, well being) in cancer have used very heterogeneous measures and have produced correspondingly inconsistent results. A meaningful synthesis of these findings has been lacking; thus, the objective of this review was to conduct a meta-analysis of the research on R/S and mental health. Four electronic databases were systematically reviewed, and 2073 abstracts met initial selection criteria. Reviewer pairs applied standardized coding schemes to extract indices of the correlation between R/S and mental health. In total, 617 effect sizes from 148 eligible studies were synthesized using meta-analytic generalized estimating equations, and subgroup analyses were performed to examine moderators of effects. The estimated mean correlation (Fisher z) was 0.19 (95\% confidence interval [CI], 0.16-0.23), which varied as a function of R/S dimensions: affective R/S (z 5 0.38; 95\% CI, 0.33-0.43), behavioral R/S (z 5 0.03; 95\% CI, 20.02-0.08), cognitive R/S (z 5 0.10; 95\% CI, 0.06-0.14), and ‘other’ R/S (z 5 0.08; 95\% CI, 0.03-0.13). Aggregate, study-level demographic and clinical factors were not predictive of the relation between R/S and mental health. There was little indication of publication or reporting biases. The correlation between R/S and mental health generally was positive. The strength of that correlation was modest and varied as a function of the R/S dimensions and mental health domains assessed. The identification of optimal R/S measures and more sophisticated methodological approaches are needed to advance research. Cancer 2015;000:000000. VC 2015 American Cancer Society.},
	language = {en},
	number = {21},
	urldate = {2020-04-13},
	journal = {Cancer},
	author = {Salsman, John M. and Pustejovsky, James E. and Jim, Heather S. L. and Munoz, Alexis R. and Merluzzi, Thomas V. and George, Login and Park, Crystal L. and Danhauer, Suzanne C. and Sherman, Allen C. and Snyder, Mallory A. and Fitchett, George},
	month = nov,
	year = {2015},
	pages = {3769--3778},
	file = {Salsman et al. - 2015 - A meta-analytic approach to examining the correlat.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\KRAR9YH5\\Salsman et al. - 2015 - A meta-analytic approach to examining the correlat.pdf:application/pdf}
}

@article{sherman_meta-analytic_2015,
	title = {A meta-analytic review of religious or spiritual involvement and social health among cancer patients: {Religion}/{Spirituality} and {Social} {Health}},
	volume = {121},
	copyright = {All rights reserved},
	issn = {0008543X},
	shorttitle = {A meta-analytic review of religious or spiritual involvement and social health among cancer patients},
	url = {http://doi.wiley.com/10.1002/cncr.29352},
	doi = {10.1002/cncr.29352},
	language = {en},
	number = {21},
	urldate = {2020-04-13},
	journal = {Cancer},
	author = {Sherman, Allen C. and Merluzzi, Thomas V. and Pustejovsky, James E. and Park, Crystal L. and George, Login and Fitchett, George and Jim, Heather S. L. and Munoz, Alexis R. and Danhauer, Suzanne C. and Snyder, Mallory A. and Salsman, John M.},
	month = nov,
	year = {2015},
	pages = {3779--3788},
	file = {Sherman et al. - 2015 - A meta-analytic review of religious or spiritual i.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\XQE4EJFQ\\Sherman et al. - 2015 - A meta-analytic review of religious or spiritual i.pdf:application/pdf}
}

@article{shadish_d_2014,
	title = {A \textit{d} -statistic for single-case designs that is equivalent to the usual between-groups \textit{d} -statistic},
	volume = {24},
	copyright = {All rights reserved},
	issn = {0960-2011, 1464-0694},
	url = {http://www.tandfonline.com/doi/abs/10.1080/09602011.2013.819021},
	doi = {10.1080/09602011.2013.819021},
	language = {en},
	number = {3-4},
	urldate = {2020-04-13},
	journal = {Neuropsychological Rehabilitation},
	author = {Shadish, William R. and Hedges, Larry V. and Pustejovsky, James E. and Boyajian, Jonathan G. and Sullivan, Kristynn J. and Andrade, Alma and Barrientos, Jeannette L.},
	month = jul,
	year = {2014},
	pages = {528--553},
	file = {Shadish et al. - 2014 - A idi -statistic for single-case designs that.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\QQR92Y5Q\\Shadish et al. - 2014 - A idi -statistic for single-case designs that.pdf:application/pdf}
}

@article{dorner_organizing_2011,
	title = {Organizing for instruction: {A} comparative study of public, charter, and {Catholic} schools},
	volume = {12},
	copyright = {All rights reserved},
	issn = {1389-2843, 1573-1812},
	shorttitle = {Organizing for instruction},
	url = {http://link.springer.com/10.1007/s10833-010-9147-5},
	doi = {10.1007/s10833-010-9147-5},
	abstract = {Guided by theories of institutions, organizations, and sense-making, this manuscript examines how public, charter, and Catholic school staff in a large urban area organize for instruction and respond to educational change. To build theory about institutional processes of ‘‘organizing’’ from participants’ perspectives, data included a survey regarding staff networks (N = 271) and semi-structured, qualitative interviews (n = 49). Findings demonstrate that all 11 schools in this study reﬂected the current reform environment with its focus on managing instruction. However, staff from different kinds of schools organized in distinct ways. Most charter and Catholic school staff described obtaining information about instruction through ‘‘organic’’ relationships using the metaphor of family to deﬁne their work situations. Alternatively, public schools tended to be ‘‘mechanistic,’’ with staff viewing themselves as professionals who were focused on standards and testing. One charter school, however, combined organic and mechanistic characteristics demonstrating the contagion that occurs among organizations in the same institutional sector and the reach that institutional policy scripts, such as No Child Left Behind, have in changing instructional practice at all kinds of schools.},
	language = {en},
	number = {1},
	urldate = {2020-04-13},
	journal = {Journal of Educational Change},
	author = {Dorner, Lisa M. and Spillane, James P. and Pustejovsky, James},
	month = feb,
	year = {2011},
	pages = {71--98},
	file = {Dorner et al. - 2011 - Organizing for instruction A comparative study of.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\DNAKH4JT\\Dorner et al. - 2011 - Organizing for instruction A comparative study of.pdf:application/pdf}
}

@article{pustejovsky_understanding_nodate,
	title = {{UNDERSTANDING} {TEACHER} {LEADERSHIP} {IN} {MIDDLE} {SCHOOL} {MATHEMATICS}: {A} {COLLABORATIVE} {RESEARCH} {EFFORT}},
	copyright = {All rights reserved},
	abstract = {We report findings from a collaborative research effort designed to examine how teachers act as leaders in their schools. We find that teachers educated by the Math in the Middle Institute act as key sources of advice for colleagues within their schools while drawing support from a network consisting of other teachers in the program and university-level advisors. In addition to reporting on our findings, we reflect on our research process, noting some of the practical challenges involved, as well as some of the benefits of collaboration.},
	language = {en},
	author = {Pustejovsky, J E and Spillane, J P and Heaton, R M and Lewis, W J},
	pages = {22},
	file = {Pustejovsky et al. - UNDERSTANDING TEACHER LEADERSHIP IN MIDDLE SCHOOL .pdf:C\:\\Users\\jep2963\\Zotero\\storage\\ASIWESCN\\Pustejovsky et al. - UNDERSTANDING TEACHER LEADERSHIP IN MIDDLE SCHOOL .pdf:application/pdf}
}

@article{pustejovsky_question-order_2009,
	title = {Question-order effects in social network name generators},
	volume = {31},
	copyright = {All rights reserved},
	issn = {03788733},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378873309000318},
	doi = {10.1016/j.socnet.2009.06.001},
	abstract = {Social network surveys are an important tool for empirical research in a variety of ﬁelds, including the study of social capital and the evaluation of educational and social policy. A growing body of methodological research sheds light on the validity and reliability of social network survey data regarding a single relation, but much less attention has been paid to the measurement of multiplex networks and the validity of comparisons among criterion relations. In this paper, we identify ways that surveys designed to collect multiplex social network data might be vulnerable to question-order effects. We then test several hypotheses using a split-ballot experiment embedded in an online multiple name generator survey of teachers’ advice networks, collected for a study of complete networks. We conclude by discussing implications for the design of multiple name generator social network surveys.},
	language = {en},
	number = {4},
	urldate = {2020-04-13},
	journal = {Social Networks},
	author = {Pustejovsky, James E. and Spillane, James P.},
	month = oct,
	year = {2009},
	pages = {221--229},
	file = {Pustejovsky and Spillane - 2009 - Question-order effects in social network name gene.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\4UP7PWB6\\Pustejovsky and Spillane - 2009 - Question-order effects in social network name gene.pdf:application/pdf}
}

@article{harris_taking_2008,
	title = {Taking a distributed perspective: {Epistemological} and methodological tradeoffs in operationalizing the leader‐plus aspect},
	volume = {46},
	copyright = {All rights reserved},
	issn = {0957-8234},
	shorttitle = {Taking a distributed perspective},
	url = {https://www.emerald.com/insight/content/doi/10.1108/09578230810863262/full/html},
	doi = {10.1108/09578230810863262},
	abstract = {Purpose – This paper is concerned with the epistemological and methodological challenges involved in studying the distribution of leadership across people within the school – the leader-plus aspect of a distributed perspective, which it aims to investigate.},
	language = {en},
	number = {2},
	urldate = {2020-04-13},
	journal = {Journal of Educational Administration},
	author = {Spillane, James P. and Camburn, Eric M. and Pustejovsky, James and Stitziel Pareja, Amber and Lewis, Geoff},
	editor = {Harris, Alma},
	month = mar,
	year = {2008},
	pages = {189--213},
	file = {Spillane et al. - 2008 - Taking a distributed perspective Epistemological .pdf:C\:\\Users\\jep2963\\Zotero\\storage\\AQYI9AQJ\\Spillane et al. - 2008 - Taking a distributed perspective Epistemological .pdf:application/pdf}
}

@incollection{harris_taking_2009,
	address = {Dordrecht},
	title = {Taking a {Distributed} {Perspective} in {Studying} {School} {Leadership} and {Management}: {The} {Challenge} of {Study} {Operations}},
	copyright = {All rights reserved},
	isbn = {978-1-4020-9736-2 978-1-4020-9737-9},
	shorttitle = {Taking a {Distributed} {Perspective} in {Studying} {School} {Leadership} and {Management}},
	url = {http://link.springer.com/10.1007/978-1-4020-9737-9_4},
	language = {en},
	urldate = {2020-04-13},
	booktitle = {Distributed {Leadership}},
	publisher = {Springer Netherlands},
	author = {Spillane, James P. and Camburn, Eric M. and Pustejovsky, James and Pareja, Amber Stitziel and Lewis, Geoff},
	editor = {Harris, Alma},
	year = {2009},
	doi = {10.1007/978-1-4020-9737-9_4},
	pages = {47--80},
	file = {Spillane et al. - 2009 - Taking a Distributed Perspective in Studying Schoo.pdf:C\:\\Users\\jep2963\\Zotero\\storage\\WUVZHKV5\\Spillane et al. - 2009 - Taking a Distributed Perspective in Studying Schoo.pdf:application/pdf}
}
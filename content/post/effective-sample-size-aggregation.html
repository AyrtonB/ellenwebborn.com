---
title: Effective sample size aggregation
authors:
- admin
date: '2019-01-22'
slug: effective-sample-size-aggregation
categories: []
tags:
  - econometrics
  - causal inference
  - weighting
header:
  caption: ''
  image: ''
---



<p>In settings with independent observations, sample size is one way to quickly characterize the precision of an estimate. But what if your estimate is based on <em>weighted</em> data, where each observation doesn’t necessarily contribute to equally to the estimate? Here, one useful way to gauge the precision of an estimate is the <em>effective sample size</em> or ESS. Suppose that we have <span class="math inline">\(N\)</span> independent observations <span class="math inline">\(Y_1,...,Y_N\)</span> drawn from a population with standard deviation <span class="math inline">\(\sigma\)</span>, and that observation <span class="math inline">\(i\)</span> receives weight <span class="math inline">\(w_i\)</span>. We take the weighted sample mean
<span class="math display">\[
\tilde{y} = \frac{1}{W} \sum_{i=1}^N w_i Y_i, \qquad \text{where} \qquad W = \sum_{i=1}^N w_i.
\]</span>
with sampling variance
<span class="math display">\[
\text{Var}(\tilde{y}) = \frac{\sigma^2}{W^2} \sum_{i=1}^N w_i^2.
\]</span></p>
<p>The ESS is the number of observations from an equally weighted sample that would yield the same level of precision as the weighted sample mean. In an equally weighted sample of size <span class="math inline">\(\tilde{N}\)</span>, the variance would be simply <span class="math inline">\(\sigma^2 / \tilde{N}\)</span>, and so ESS is the value of <span class="math inline">\(\tilde{N}\)</span> that solves
<span class="math display">\[
\frac{\sigma^2}{\tilde{N}} = \frac{\sigma^2}{W^2} \sum_{i=1}^N w_i^2.
\]</span></p>
<p>Re-arranging, the ESS is thus defined as
<span class="math display">\[
\tilde{N} = \frac{W^2}{\sum_{i=1}^N w_i^2}.
\]</span></p>
<p>The ESS is reported in several packages for propensity score weighting, including <a href="https://CRAN.R-project.org/package=twang">twang</a> and <a href="https://CRAN.R-project.org/package=optweight">optweight</a>. In the propensity score context, ESS is a useful measure for comparing different sets of estimated propensity weights, in that weights (or propensity score models/matching methods) that have a larger ESS will yield a more precise estimate of a treatment effect. Given two sets of weights that achieve equivalent degrees of balance, the weights with larger ESS are thus preferable. Methods introduced by <a href="https://doi.org/10.1080/01621459.2015.1023805">Zubizarreta (2015)</a>—and implemented in the <a href="https://CRAN.R-project.org/package=optweight">optweight</a> package—take this logic a step further by using ESS as an objective function to be minimized, subject to specified balancing constraints.</p>
<div id="multi-site-effective-sample-size" class="section level1">
<h1>Multi-site effective sample size</h1>
<p>Two of my recent projects have involved applying propensity score weighting methods in multi-site settings, where we are interested in estimating site-specific treatment effects as well as an overall aggregate effect. It is straight-forward to calculate an ESS for each site, but how then should we aggregate the ESS across sites to characterize the precision of the overall estimate? Several times now, I have found myself having to re-derive the aggregated ESS, and so I am going to work through it here now so as to save future-me (and perhaps you, dear reader) some time.</p>
<p>Suppose that we have <span class="math inline">\(J\)</span> sites, <span class="math inline">\(n_j\)</span> observations from site <span class="math inline">\(j\)</span> for <span class="math inline">\(j = 1,...,J\)</span>, and total sample size <span class="math inline">\(N = \sum_{j=1}^J n_j\)</span>. Observation <span class="math inline">\(i\)</span> from site <span class="math inline">\(j\)</span> has outcome <span class="math inline">\(Y_{ij}\)</span> and weight <span class="math inline">\(w_{ij}\)</span>. The site-specific weighted average at site <span class="math inline">\(j\)</span> is then
<span class="math display">\[
\tilde{y}_j = \frac{1}{W_j} \sum_{i=1}^{n_j} w_{ij} Y_{ij}, \qquad \text{where} \qquad W_j = \sum_{i=1}^{n_j} w_{ij}
\]</span>
and the overall average is
<span class="math display">\[
\tilde{y} = \frac{1}{N} \sum_{j=1}^J n_j \ \tilde{y}_j = \frac{1}{N} \sum_{j=1}^J \sum_{i=1}^{n_j} \frac{n_j w_{ij}}{W_j} Y_{ij}.
\]</span></p>
<p>For calculating the overall average, observation <span class="math inline">\(i\)</span> from unit <span class="math inline">\(j\)</span> contributes weight <span class="math inline">\(u_{ij} = n_j w_{ij} / W_j\)</span>.</p>
<p>Using these unit-specific weights, the effective sample size for the overall average is
<span class="math display">\[
ESS = \frac{N^2}{\sum_{j=1}^J \sum_{i=1}^{n_j} u_{ij}^2}.
\]</span>
We can also define a site-specific ESS for site <span class="math inline">\(j\)</span>:
<span class="math display">\[
ESS_j = \frac{W_j^2}{\sum_{i=1}^{n_j} w_{ij}^2}.
\]</span></p>
<p>Using the decomposition of the weights as <span class="math inline">\(u_{ij} = n_j w_{ij} / W_j\)</span>, the overall ESS can be written as
<span class="math display">\[
ESS = \frac{N^2}{\sum_{j=1}^J n_j^2 \left(\sum_{i=1}^{n_j} w_{ij}^2 / W_j^2\right)}.
\]</span>
Noting that the term in the parentheses of the denominator is equivalent to <span class="math inline">\(1 / ESS_j\)</span>, the overall ESS can therefore be written in terms of the site-specific ESSs and sample sizes:
<span class="math display">\[
ESS = \frac{N^2}{\sum_{j=1}^J n_j^2 / ESS_j}.
\]</span></p>
<p>There you go. Future me will thank me for this!</p>
</div>
